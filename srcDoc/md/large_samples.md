# Using RTI Perftest for Large Samples

*RTI Perftest* can send samples from 28 Bytes to 2,147,483,135 Bytes (2 GBytes - 512 Bytes - 8 Bytes), which corresponds to the maximum payload that *RTI Connext DDS* is able to send in a single sample.

The size of data is configured by the Command-Line Parameter `-dataLen <bytes>`. Depending on this parameter, *RTI Perftest* will automatically configure certain *RTI Connext DDS* behaviors.

In the case that the sample size is smaller or equal to 63000 Bytes, *RTI Perftest* will, by default, use types with Bounded-Sequences (bound set to 63000 elements). If the sample size is bigger than 63000 Bytes, *RTI Perftest* will automatically switch to equivalent types to the ones mentioned previously, but with Unbounded-Sequences.

The reason behind this behavior is that in the case when *RTI Perftest* uses Unbounded-Sequences, *RTI Connext DDS* will not pre-allocate the sequences to their maximum size (as opposite as when using bounded sequences). For Unbounded-Members, the code generated by *RTI Connext DDS* will de-serialize the samples by dynamically allocating and de-allocating memory to accommodate the actual size of the unbounded member. Unbounded-Sequences and strings are also supported with DynamicData (Command-Line parameter `-DynamicData`).

Apart from the use of Unbounded-Sequences, by setting samples bigger than 63000 Bytes, *RTI Perftest* will enable the use of *Asynchronous Publishing*, as set *RTI Connext DDS* default flow controller.

The case where the user wants to use Unbounded-Sequences, Asynchronous Publishing or a Flow Controller different than the default one but the sample size is smaller than 63000 Bytes is also supported. These behaviors can be achieved by using the Command-Line Parameters `-unbounded <managerMemory>`, `-asynchronous` and `-flowController`, see the **Test Parameters** section for more details.

---

## Adjusting the configuration

Find here an example where the sample size is configured to 1GB:

* Publisher:

```
bin/<architecture>/<release or debug>/perftest_cpp -pub -dataLen 1073741824
```

* Subscriber:

```
bin/<architecture>/<release or debug>/perftest_cpp -sub -dataLen 1073741824
```

This is a perfectly valid configuration, accepted by *RTI Perftest*, however, in certain cases, the communication in this scenario will be limited or non-optimal, due to the large sample size. Therefore some extra tuning might be required:

#### By using the parameter `-sendQueueSize <number>`

The default value for the Send Queue in the Writer side is `50`. That might be a very high value, and the *RTI Connext DDS* middleware might not perform in optimal conditions. Therefore, for large data samples it is recommended to reduce the send Queue to lower values.

#### By using the parameter `-pubRate <samples/s>`

This parameter can be used in order to limit the frequency in which *RTI Perftest* publishes samples. This can help reducing the number of packages in the network, helping to achieve better Latency and Throughput numbers.

#### By using a flow controller `-flowController <default,1Gbps,10Gbps>`

Since the sample size is bigger than 63000 Bytes, *RTI Perftest* will enable Asynchronous Publing. By enabling that, you also make use of the default *Flow Controller*, which might not be optimal. It might be a good practice to specify a *Flow Controller* tailored for the network where the scenario is.

*RTI Perftest* provides options to use a flow controller designed for a 10Gbps network and a 1Gbps one. However, by accessing to the `perftest_qos_profiles.xml` configuration file it is possible to modify these 2 Flow Controllers and tailor them to specific network requirements.

``` xml
<qos_profile name="BaseProfileQos">
    <participant_qos>
        . . .
        <property>
            <value>
                <element>
                    <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.max_tokens</name>
                    <value>300</value>
                </element>
                <element>
                    <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.tokens_added_per_period</name>
                    <value>200</value>
                </element>
                <element>
                    <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.bytes_per_token</name>
                    <value>65536</value>
                </element>
                <element>
                    <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.period.sec</name>
                    <value>0</value>
                </element>
                <element>
                    <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.period.nanosec</name>
                    <value>10000000</value>
                </element>
            </value>
        </property>
        . . .
    </participant_qos>
</qos_profile>
```

The specific values for the Flow Controller and the Send Queue will highly depend on the scenario and machines performing the test, but as a general suggestion, these changes are recommended:

* Publisher:

```
bin/<architecture>/<release or debug>/perftest_cpp -pub -dataLen 1073741824 -sendQueueSize 1 -flowController 1Gbps
```

* Subscriber:

```
bin/<architecture>/<release or debug>/perftest_cpp -sub -dataLen 1073741824
```

## Large Samples in Java

When using the *RTI Perftest* implementation for *Java* and large data samples, the following error may appear:

```
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
```

The the memory reserved for the heap is not enough in this case, the way how to solve this is by increasing the size we allow *Java* to reserve. This can be done by using the Command-Line Parameter `-Xmx` in the scripts used to run the Java examples: `bin/Release/perftest_java.sh` and `bin\Release\perftest_java.bat`. The increased amount will depend on the `-dataLen` parameter and the memory specifications of device where *RTI Perftest* is running.