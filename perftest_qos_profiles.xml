<?xml version="1.0" encoding="iso-8859-1"?>

<!--
(c) 2005-2017  Copyright, Real-Time Innovations, Inc. All rights reserved.
Subject to Eclipse Public License v1.0; see LICENSE.md for details.
-->

<!--
This file contains the QoS configurations used by the RTI PerfTest, a
performance test for measuring the latency of the middleware at different
throughput levels.

The format of this file is described in the RTI Connext Core Libraries
and Utilities User's Manual in the chapter titled "Configuring QoS with XML."
-->

<!--
Equivalence between variable names and command-line options within the source code:

_DataLen variable name corresponds to the command-line option -dataLen
_SendQueueSize variable name corresponds to the command-line option -sendQueueSize
_InstanceCount variable name corresponds to the command-line option -instances
_InstanceHashBuckets variable name corresponds to the command-line option -instanceHashBuckets
_KeepDurationUsec variable name corresponds to the command-line option -keepDurationUsec

-->

<dds xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:noNamespaceSchemaLocation="https://community.rti.com/schema/5.3.0/rti_dds_profiles.xsd">

  <qos_library name="PerftestQosLibrary">

    <!-- ================================================================= -->
    <!-- Base QoS Profile                                            -->
    <!-- ================================================================= -->

    <!--
    This profile is used as the base for all the profiles defined in this XML file.
    -->

    <qos_profile name="BaseProfileQos">
      <participant_qos>
        <!-- === Participant Configuration: ================================

        The base configuration of the DomainParticipant object.

        This element corresponds to the DomainParticipantQos type, which is described
        in detail in the API Reference HTML documentation. Each child element corresponds
        to a field in that structure with the same name. Any parameter not listed
        here will pick up the documented default value.
        -->
        <receiver_pool>
          <!--
          The receive buffer is used by the receive thread to store the raw data
          that arrives over the transport.

          The ReceiverPoolQosPolicy's buffer_size should be set to be the same value
          as the maximum ::NDDS_Transport_Property_t::message_size_max across all of
          the transports being used.
          -->
          <buffer_size>65536</buffer_size>
        </receiver_pool>

        <resource_limits>
          <!--
          Maximum size of a serialized type code.

          This parameter limits the size of the type code that a DomainParticipant
          is able to store and propagate for data types.
          -->
          <type_code_max_serialized_length>2048</type_code_max_serialized_length>

          <!--
          Maximum string length of the properties associated with the DomainParticipant.

          The string length is defined as the cumulative length, in bytes, including the
          null terminating characters, of all the (name,value) pairs associated with the
          DomainParticipant properties.
          -->
          <participant_property_string_max_length>4096</participant_property_string_max_length>

          <!--
          Maximum number of properties associated with the DomainParticipant. Default is 32.
          -->
          <participant_property_list_max_length>64</participant_property_list_max_length>
          <!--
          Maximum length for content filter property in the DomainParticipant. Default is 256.
          -->
          <contentfilter_property_max_length>512</contentfilter_property_max_length>
        </resource_limits>

        <!--
        Specifies which built-in transports are used.

        Three different transport plug-ins are built into the Connext core
        libraries (for most supported target platforms): UDPv4, shared memory, and
        UDPv6.

        By default RTI Perftest uses UDPv4|SHMEM, default values for RTI
        Connext DDS. By using the command-line option -transport we enabled
        the use of:

        - UDPv4
        - UDPv6
        - SHMEM
        - TCP
        - TLS
        - DTLS
        - WAN

        For custom transport settings, modify this profile.
        -->

        <!--
        <transport_builtin>
          <mask>UDPv4|SHMEM</mask>
        </transport_builtin>
        -->

        <property>
          <value>

            <!--
            Specifies the configuration to be used with the UDPv4 built-in transport.
            -->
            <element>
              <name>dds.transport.UDPv4.builtin.parent.message_size_max</name>
              <value>65536</value>
            </element>
            <element>
              <name>dds.transport.UDPv4.builtin.send_socket_buffer_size</name>
              <value>524288</value>
            </element>
            <element>
              <name>dds.transport.UDPv4.builtin.recv_socket_buffer_size</name>
              <value>2097152</value>
            </element>

            <!--
            Specifies the configuration to be used with the SHMEM built-in transport.

            Important: The commented setting is configured automatically within the
            source code. The default value of _DataLen is 100.

            Value set in the source code:

            <element>
              <name>dds.transport.shmem.builtin.received_message_count_max</name>
              <value>2097152/_DataLen</value>
            </element>
            -->
            <element>
              <name>dds.transport.shmem.builtin.parent.message_size_max</name>
              <value>65536</value>
            </element>
            <element>
              <name>dds.transport.shmem.builtin.receive_buffer_size</name>
              <value>2097152</value>
            </element>

            <!--
            Specifies the configuration to be used with the TCP transport.

            If TCP is enabled using -transport TCP, the load_plugins property is set
            within the source code.

            Important: nddstransporttcp.dll is located in NDDSHOME/lib/<architecture>.
            That folder must be added to the PATH on Windows systems and LD_LIBRARY_PATH
            on UNIX-based systems in order to load this library properly. If you are
            compiling PerfTest using CSHARP, you must also add the folder
            NDDSHOME/lib/i86Win32VS<version> or NDDSHOME/lib/x64Win64VS<version> depending
            on the machine.

            <element>
              <name>dds.transport.load_plugins</name>
              <value>dds.transport.TCPv4.tcp1</value>
            </element>
            -->
            <element>
              <name>dds.transport.TCPv4.tcp1.library</name>
              <value>nddstransporttcp</value>
            </element>
            <element>
              <name>dds.transport.TCPv4.tcp1.create_function</name>
              <value>NDDS_Transport_TCPv4_create</value>
            </element>
            <element>
              <name>dds.transport.TCPv4.tcp1.disable_nagle</name>
              <value>1</value>
            </element>
            <element>
              <name>dds.transport.TCPv4.tcp1.parent.message_size_max</name>
              <value>65536</value>
            </element>

            <!-- Defining flow controller 10Gbps. This will not enable it. -->
            <element>
              <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.max_tokens</name>
              <value>300</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.tokens_added_per_period</name>
              <value>200</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.bytes_per_token</name>
              <value>65536</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.period.sec</name>
              <value>0</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.10Gbps.token_bucket.period.nanosec</name>
              <value>10000000</value>
            </element>

            <!-- Defining flow controller 1Gbps. This will not enable it. -->
            <element>
              <name>dds.flow_controller.token_bucket.1Gbps.token_bucket.max_tokens</name>
              <value>30</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.1Gbps.token_bucket.tokens_added_per_period</name>
              <value>20</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.1Gbps.token_bucket.bytes_per_token</name>
              <value>65536</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.1Gbps.token_bucket.period.sec</name>
              <value>0</value>
            </element>
            <element>
              <name>dds.flow_controller.token_bucket.1Gbps.token_bucket.period.nanosec</name>
              <value>10000000</value>
            </element>

          </value>
        </property>

        <!--
        Specifies the participant name. This setting is useful when using monitoring
        applications.
        -->
        <participant_name>
          <name>PerfTest Participant</name>
        </participant_name>

      </participant_qos>

      <!-- === Publisher Configuration: ================================= 
        
      The base configuration of the Publisher object.

      This element corresponds to the PublisherQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <publisher_qos>
        <presentation>
          <!--
          Access Scope: Determines the largest scope spanning the entities
          for which the order and coherency of changes can be preserved.
          
          Ordered Access: Specifies support for ordered access to the samples
          received at the subscription end.
          -->
          <access_scope>TOPIC_PRESENTATION_QOS</access_scope>
          <ordered_access>true</ordered_access>
        </presentation>
      </publisher_qos>

      <!-- === Subscriber Configuration: ================================= 
      
      The base configuration of the Subscriber object.

      This element corresponds to the SubscriberQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <subscriber_qos>
        <presentation>
          <!--
          Access Scope: Determines the largest scope spanning the entities
          for which the order and coherency of changes can be preserved.
          
          Ordered Access: Specifies support for ordered access to the samples
          received at the subscription end.
          -->
          <access_scope>TOPIC_PRESENTATION_QOS</access_scope>
          <ordered_access>true</ordered_access>
        </presentation>
      </subscriber_qos>
      
      <!-- === DataWriter Configuration: ==================================
      
      The base configuration of the DataWriter object that produces throughput
      data (the -pub side of the application).

      This element corresponds to the DataWriterQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <datawriter_qos>
        <resource_limits>
          <!--
          The number of instances for which the throughput DataWriter will
          allocate space. The throughput topic is not keyed, so there is no 
          need for more than one instance.

          See Section 2.2 "Data Types, Topics, Keys, Instances, and Samples"
          in the Connext Core Libraries and Utilities User's Manual 
          for more information about keys and instances.
          
          Important: These settings are configured automatically within the 
          source code. The default value of _InstanceCount is 1. The default
          value of _InstanceHashBuckets is -1.
          
          <max_instances>_InstanceCount</max_instances>
          <initial_instances>_InstanceCount</initial_instances>
          
          if _InstanceCount is greater than 1  
            if _InstanceHashBuckets is greater than 0
              <instance_hash_buckets>_InstanceHashBuckets</instance_hash_buckets>
            
            if _InstanceHashBuckets is equal or lower than 0
              <instance_hash_buckets>_InstanceCount</instance_hash_buckets>
          
          -->
        </resource_limits>
        
        <protocol>
            <rtps_reliable_writer>
                <!--
                When positive acknowledgements have been disabled, the DataWriter will 
                consider samples as positively "acknowledged" after this duration has 
                elapsed if it has not heard otherwise.
                
                We disable the positive acknowledgements in perftest by using:
                -disablePositiveAcks. You can alternatively enable them via QoS by
                adding <disable_positive_acks>true</disable_positive_acks> in the
                <protocol> QoS of the DW and DR of the ThroughputQoS and LatencyQoS.

                The default value of _KeepDurationUsec can be configured here or via the
                command line parameter -keepDuration.
                -->
                <disable_positive_acks_min_sample_keep_duration>
                    <sec>DURATION_ZERO_SEC</sec>
                    <nanosec>100000</nanosec>
                </disable_positive_acks_min_sample_keep_duration>
            </rtps_reliable_writer>
        </protocol>

      </datawriter_qos>

      <!-- === DataReader Configuration: ================================= -->

      <!--
      The base configuration of the DataReader object that consumes throughput
      data (the -sub side of the application).

      This element corresponds to the DataReaderQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <datareader_qos>
        <resource_limits>
          <!--
          The initial and maximum number of instances for which the middleware
          will allocate space. See the corresponding DataWriterQos comment above
          for more information. 
          
          Important: This settings are configured automatically within the source code.
          The default value of _InstanceCount is 1.
          The default value of _InstanceMaxCountReader is -1.
          The default value of _InstanceHashBuckets is -1.
          
          <max_instances>_InstanceMaxCountReader</max_instances>
          <initial_instances>_InstanceCount</initial_instances>
          
          if _InstanceCount is greater than 1 and 
            if _InstanceHashBuckets is greater than 0
              <instance_hash_buckets>_InstanceHashBuckets</instance_hash_buckets>
            
            if _InstanceHashBuckets is equal or lower than 0
              <instance_hash_buckets>_InstanceCount</instance_hash_buckets>
          
          -->
        </resource_limits>
      </datareader_qos>
      
    </qos_profile>

    <!-- ================================================================= -->
    <!-- Throughput QoS Profile                                            -->
    <!-- ================================================================= -->

    <!--
    This profile is used by the throughput-testing portion of the application,
    provided that positive acknowledgements have not been disabled with the
    '-noPositiveAcks' command-line argument or 'use positive acks = false'
    in the .ini configuration file.
    -->
    <qos_profile name="ThroughputQos" base_name="BaseProfileQos">

      <!-- === DataWriter Configuration: ================================= 
      
      The base configuration of the DataWriter object that produces throughput
      data (the -pub side of the application).

      This element corresponds to the DataWriterQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <datawriter_qos>
        <writer_resource_limits>
          <max_remote_reader_filters>256</max_remote_reader_filters>
        </writer_resource_limits>
        <!--
        Setting history.kind = KEEP_ALL, Connext will attempt to maintain
        and deliver all the values of the instance to existing subscribers. 
        The resources that Connext can use to keep this history are limited
        by the settings of the RESOURCE_LIMITS.
        -->
        <history>
          <kind>KEEP_ALL_HISTORY_QOS</kind>
        </history>
        <!--
        Setting reliability.kind = RELIABLE_RELIABILITY_QOS, data samples 
        originating from a single DataWriter cannot be made available to the
        DataReader if there are previous data samples that have not been 
        received yet due to a communication error.

        The default value of reliability.kind is RELIABLE_RELIABILITY_QOS.
        The reliability.kind can be modified to BEST_EFFORT_RELIABILITY_QOS
        by using the command-line option -bestEffort.
        -->
        <reliability>
          <kind>RELIABLE_RELIABILITY_QOS</kind>
          <max_blocking_time>
            <sec>DURATION_INFINITE_SEC</sec>
            <nanosec>DURATION_INFINITE_NSEC</nanosec>
          </max_blocking_time>
        </reliability>

        <resource_limits>
          <!--
          The number of data samples for which the DataWriter will allocate
          space. The throughput test is configured without durability, meaning
          that when all DataReaders have acknowledged a sample, the DataWriter
          will discard it. The values below, then, effectively indicate how
          far ahead of the slowest reader the writer is able to get before it
          will block waiting for the reader(s) to catch up.

          See the parallel DataReaderQos comment above for more information
          about the relationships between these three values.
          
          Important: These settings are configured automatically within the 
          source code.
            _SendQueueSize = 50 (default)
            _SendQueueSize can be configured using the command-line option -sendQueueSize <value>
          
          if batching is not set:
            <max_samples>_SendQueueSize</max_samples>
            <initial_samples>_SendQueueSize</initial_samples>
            <max_samples_per_instance>_SendQueueSize</max_samples_per_instance>
            
          if batching is set:
            <max_samples>DDS_LENGTH_UNLIMITED</max_samples>
            <initial_samples>_SendQueueSize</initial_samples>
            <max_samples_per_instance>DDS_LENGTH_UNLIMITED</max_samples_per_instance>
          -->
        </resource_limits>
        
        <protocol>
          <rtps_reliable_writer>
            <!--
            When the writer's cache gets down to this number of samples, it
            will slow the rate at which it sends heartbeats to readers.
            
            Important: This setting is configured automatically within the source code.
            <low_watermark>_SendQueueSize * 0.1</low_watermark>
            -->

            <!--
            When the writer's cache is filled to this level, it will begin
            sending heartbeats at a faster rate in order to spur faster
            acknowledgements (positive or negative) of its samples to allow it
            to empty its cache and avoid blocking.
            
            Important: This setting is configured automatically within the source code.
            <high_watermark>_SendQueueSize * 0.9</high_watermark>
            -->

            <!--
            Governs how often heartbeats are "piggybacked" on data samples.
            
            Important: This setting is configured automatically within the source code.
            <heartbeats_per_max_samples>_SendQueueSize * 0.1</heartbeats_per_max_samples>
            -->

            <!-- 
            Minimum and maximum size of send window of unacknowledged samples.

            Important: These settings are configured automatically within the source code.
            <min_send_window_size>datawriter_qos.resource_limits.max_samples</min_send_window_size>
            <max_send_window_size>datawriter_qos.resource_limits.max_samples</max_send_window_size>
            -->

            <!--
            If the number of samples in the writer's cache hasn't risen to
            high_watermark, this is the rate at which the DataWriter will
            send out periodic heartbeats.
            -->
            <heartbeat_period>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>10000000</nanosec>
            </heartbeat_period>
            
            <!--
            If the number of samples in the writer's cache has risen to
            high_watermark, and has not yet fallen to low_watermark, this is
            the rate at which the writer will send periodic heartbeats to
            its readers.
            -->
            <fast_heartbeat_period>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>1000000</nanosec>
            </fast_heartbeat_period>

            <!--
            If a durable reader starts up after the writer already has some
            samples in its cache, this is the rate at which it will heartbeat
            the new reader. It should generally be a shorter period of time
            than the normal heartbeat period in order to help the new reader
            catch up.
            -->
            <late_joiner_heartbeat_period>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>10000000</nanosec>
            </late_joiner_heartbeat_period>

            <!--
            The number of times a reliable writer will send a heartbeat to
            a reader without receiving a response before it will consider the
            reader to be inactive and no longer await acknowledgements before
            discarding sent data.
            -->
            <max_heartbeat_retries>LENGTH_UNLIMITED</max_heartbeat_retries>

            <!--
            When a DataWriter receives a negative acknowledgement (NACK) from
            a DataReader for a particular data sample, it will send a repair
            packet to that reader.

            The amount of time the writer waits between receiving the NACK and
            sending the repair will be a random value between the minimum
            and maximum values specified here. Narrowing the range, and
            shifting it towards zero, will make the writer more reactive.
            However, by leaving some delay you increase the chance that the
            writer will learn of additional readers that missed the same data,
            in which case it will be able to send a single multicast repair
            instead of multiple unicast repairs, thereby using the available
            network bandwidth more efficiently. The higher the fanout in your
            system (i.e., the more readers per writer), and the greater the
            load on your network, the more you should consider specifying a
            non-zero delay here.
            -->
            <min_nack_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </min_nack_response_delay>
            <max_nack_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </max_nack_response_delay>
          </rtps_reliable_writer>
          
        </protocol>

        <!--
        When sending many small data-samples, you can increated network efficiency 
        by batching multiple samples together in a single protocol-level message 
        (usually corresponding to a single network datagram). Batching can offer very 
        substantial throughput gains, but often at the expense of latency, although 
        in some configurations, the latency penalty can be very small or zero, 
        possibly even negative.
        -->

        <!-- 
        Important: This setting is configured automatically within the source code,
        but only if batching is enabled. _SendQueueSize = 50 (default)
        <writer_resource_limits>
          <max_batches>_SendQueueSize</max_batches>
        </writer_resource_limits>
        -->

        <batch>
          <!--
          This profile does not enable batching, although the remaining
          batching settings are configured as if it did. To enable the batch
          configuration below, turn batching on using the app's command-line
          or INI file.
          -->
          <enable>false</enable>

          <!--
          Batches can be "flushed" to the network based on a maximum size.
          This size can be based on the total number of bytes in the
          accumulated data samples, the total number of bytes in the
          accumulated sample meta-data (e.g., timestamps, sequence numbers,
          etc.), and/or the number of samples. Whenever the first of these
          limits is reached, the batch will be flushed.
          
          Important: This setting is configured automatically within the source code.
          <max_data_bytes>_BatchSize</max_data_bytes>
          -->
          <max_meta_data_bytes>LENGTH_UNLIMITED</max_meta_data_bytes>
          <max_samples>LENGTH_UNLIMITED</max_samples>

          <!--
          The middleware will associate a source timestamp with a batch when
          it is started. The duration below indicates the amount of time that
          may pass before the middleware will insert an additional timestamp
          into the middle of an existing batch.

          Shortening this duration can give readers increased timestamp
          resolution. However, lengthening this duration
          decreases the amount of meta-data on the network, potentially
          improving throughput, especially if the data samples are very small.
          If this delay is set to an infinite time period, timestamps will
          be inserted only once per batch. Furthermore, the middleware will
          not need to check the time with each sample in the batch, reducing
          the amount of computation on the send path and potentially improving
          both latency and throughput performance.
          -->
          <source_timestamp_resolution>
            <sec>DURATION_INFINITE_SEC</sec>
            <nanosec>DURATION_INFINITE_NSEC</nanosec>
          </source_timestamp_resolution>

          <!--
          The maximum flush delay. A batch is flushed automatically after the 
          delay specified by this parameter. As its value is DURATION_INFINITE, 
          the flush event will be triggered by max_data_bytes.
          -->
          <max_flush_delay>
            <sec>DURATION_INFINITE_SEC</sec>
            <nanosec>DURATION_INFINITE_NSEC</nanosec>
          </max_flush_delay>

          <!--
          By default, the same DataWriter can be used from multiple threads.
          If you know that your application will only write data from a single
          thread, you can switch off a level of locking that occurs when
          samples are added to a batch. When sending very small samples very
          fast, this decreased overhead can improve performance.

          However, even in the case of single-threaded access, the impact of
          locking can be negligible, and deactivating the lock puts your
          application at risk of memory corruption if multiple threads do
          write to the same DataWriter - either without your knowledge or as
          a result of application maintenance. Therefore, RTI recommends that
          you only set thread_safe_write to false after detailed testing has
          confirmed that your application does indeed behave correctly and
          with improved performance.
          -->
          <thread_safe_write>false</thread_safe_write>
        </batch>

        <writer_data_lifecycle>
          <autodispose_unregistered_instances>false</autodispose_unregistered_instances>
        </writer_data_lifecycle>

      </datawriter_qos>

      <!-- === DataReader Configuration: ================================= -->

      <!--
      The base configuration of the DataReader object that consumes throughput
      data (the -sub side of the application).

      This element corresponds to the DataReaderQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <datareader_qos>

        <!--
        Setting history.kind = KEEP_ALL, Connext will attempt to maintain
        and deliver all the values of the instance to existing subscribers.
        The resources that Connext can use to keep this history are limited
        by the settings of the RESOURCE_LIMITS.
        -->
        <history>
          <kind>KEEP_ALL_HISTORY_QOS</kind>
        </history>

        <!--
        Setting reliability.kind = RELIABLE_RELIABILITY_QOS, data samples
        originating from a single DataWriter cannot be made available to the
        DataReader if there are previous data samples that have not been
        received yet due to a communication error.

        The default value of reliability.kind is RELIABLE_RELIABILITY_QOS.
        The reliability.kind can be modified to BEST_EFFORT_RELIABILITY_QOS
        by using the command-line option -bestEffort.
        -->
        <reliability>
          <kind>RELIABLE_RELIABILITY_QOS</kind>
        </reliability>

        <!--
        DurabilityQos policy specifies whether or not Connext will store and
        deliver previously published data samples to new DataReaders
        that join the network later.

        Important: durability.kind and durability.direct_communication are configured
        automatically within the source code. To modify them, use the input commands
        -durability and -noDirectCommunication.

        The default value of _DirectCommunication is true.
        The default value of _Durability is DDS_VOLATILE_DURABILITY_QOS.

        <durability>
          <kind>_Durability</kind>
          <direct_communication>_DirectCommunication</direct_communication>
        </durability>
        -->

        <resource_limits>
          <!--
          The initial and maximum number of data samples. The middleware will
          make sure to allocate space for the initial_samples, and then if
          needed, it will grow the allocated memory up to a point where it
          supports max_samples.

          For the initial number of samples we choose a number that should be
          enough for most use-cases (therefore no need to grow), but that
          should not affect the memory consumption by reserving too much
          memory.
          -->
          <max_samples>10000</max_samples>
          <initial_samples>128</initial_samples>

          <!--
          The maximum number of samples that can be stored for a single
          instance. If the throughput topic is not keyed, there is only a
          single instance, so this value should always be set the same
          as max_samples.

          For a keyed topic, you might want to use this parameter to institute
          a degree of "fairness" among the instances.
          -->
          <max_samples_per_instance>10000</max_samples_per_instance>
        </resource_limits>

        <reader_resource_limits>
          <!--
          The maximum number of samples that Connext will store from a
          single DataWriter. If you run this application with only a single
          DataWriter (that is, in a one-to-one or one-to-many configuration),
          there is no reason for this value to be set to anything less than
          max_samples. If you have many writers and need to institute
          a degree of "fairness" among them, you can decrease this value.
          -->
          <max_samples_per_remote_writer>10000</max_samples_per_remote_writer>

          <!--
          The maximum number of data samples that the application can receive
          from Connext in a single call to DataReader::read() or
          take(). If more data exists in the middleware, the application will
          need to issue multiple read()/take() calls.

          When reading data using listeners, the expected number of samples
          available for delivery in a single take() call is typically small:
          usually just one in the case of unbatched data, or the number of
          samples in a single batch in the case of batched data. When polling
          for data or using Waitsets, however, multiple samples (or batches)
          could be retrieved at once, depending on the data rate.

          A larger value for this parameter makes the API simpler to use, at
          the expense of some additional memory consumption.
          -->
          <max_samples_per_read>65536</max_samples_per_read>
        </reader_resource_limits>

        <protocol>
          <rtps_reliable_reader>
            <!--
            When the DataReader receives a heartbeat from a DataWriter
            (indicating (a) that the DataWriter still exists on the network
            and (b) what sequence numbers it has published), the following
            parameters indicate how long it will wait before replying with
            a positive (assuming they aren't disabled) or negative
            acknowledgement.

            The time the reader waits will be a random duration between
            the minimum and maximum values. Narrowing this range, and shifting
            it towards zero, will make the system more reactive. However, it
            increases the chance of (N)ACK spikes. The higher the fanout in
            your system (i.e., the number of readers per writer), the more
            you should consider specifying a range here.
            -->
            <min_heartbeat_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </min_heartbeat_response_delay>
            <max_heartbeat_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </max_heartbeat_response_delay>
          </rtps_reliable_reader>
        </protocol>
      </datareader_qos>

    </qos_profile>


    <!-- ================================================================= -->
    <!-- Latency QoS Profile                                               -->
    <!-- ================================================================= -->

    <!--
    This profile is used by the latency-testing portion of the application,
    provided that positive acknowledgements have not been disabled with the
    '-noPositiveAcks' command-line argument or 'use positive acks = false'
    INI file configuration.
    -->
    <qos_profile name="LatencyQos" base_name="BaseProfileQos">

      <!-- === DataWriter Configuration: ================================= 
      
      The base configuration of the DataWriter object that consumes latency
      data (on the -sub side of the application).

      This element corresponds to the DataWriterQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <datawriter_qos>
        <!--
        Setting history.kind = KEEP_ALL, Connext will attempt to maintain
        and deliver all the values of the instance to existing subscribers. 
        The resources that Connext can use to keep this history are limited
        by the settings of the RESOURCE_LIMITS.
        -->
        <history>
          <kind>KEEP_ALL_HISTORY_QOS</kind>
        </history>

        <!--
        Setting reliability.kind = RELIABLE_RELIABILITY_QOS, data samples 
        originating from a single DataWriter cannot be made available to the
        DataReader if there are previous data samples that have not been 
        received yet due to a communication error.

        The default value is RELIABLE_RELIABILITY_QOS.
        It can be modified to BEST_EFFORT_RELIABILITY_QOS
        using the command-line option -bestEffort.
        -->
        <reliability>
          <kind>RELIABLE_RELIABILITY_QOS</kind>
          <max_blocking_time>
            <sec>DURATION_INFINITE_SEC</sec>
            <nanosec>DURATION_INFINITE_NSEC</nanosec>
          </max_blocking_time>
        </reliability>

        <!--
        
        The Durability QoS policy specifies whether or not Connext will store and 
        deliver previously published data samples to new DataReaders that join the 
        network later.
        
        Important: durability.kind and durability.direct_communication are configured
        automatically within the source code. To modify them, use the input commands
        -durability and -noDirectCommunication.
        
        The default value of _DirectCommunication is true.
        The default value of _Durability is DDS_VOLATILE_DURABILITY_QOS
        
        if _DirectCommunication is false
          if _Durability is DDS_TRANSIENT_DURABILITY_QOS or DDS_PERSISTENT_DURABILITY_QOS
            <durability>
              <kind>_Durability</kind>
              <direct_communication>_DirectCommunication</direct_communication>
            </durability>
        -->
        
        <!--
        The number of samples for which Connext will set aside space.
        See the comments above for more information.
        -->
        <resource_limits>
          <max_samples>LENGTH_UNLIMITED</max_samples>
          <initial_samples>100</initial_samples>
          <max_samples_per_instance>LENGTH_UNLIMITED</max_samples_per_instance>
        </resource_limits>
        
        <!--
        The behavioral contract under which the DataWriter will carry out the
        reliability protocol. See the comments above for more information.
        -->
        <protocol>
          <rtps_reliable_writer>
            <low_watermark>10</low_watermark>
            <high_watermark>100</high_watermark>
            <heartbeats_per_max_samples>1000</heartbeats_per_max_samples>
            <heartbeat_period>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>10000000</nanosec>
            </heartbeat_period>
            <fast_heartbeat_period>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>1000000</nanosec>
            </fast_heartbeat_period>
            <late_joiner_heartbeat_period>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>10000000</nanosec>
            </late_joiner_heartbeat_period>
            <max_heartbeat_retries>LENGTH_UNLIMITED</max_heartbeat_retries>
            <min_nack_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </min_nack_response_delay>
            <max_nack_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </max_nack_response_delay>
            <min_send_window_size>LENGTH_UNLIMITED</min_send_window_size>
            <max_send_window_size>LENGTH_UNLIMITED</max_send_window_size>
          </rtps_reliable_writer>
        </protocol>

        <writer_data_lifecycle>
          <autodispose_unregistered_instances>false</autodispose_unregistered_instances>
        </writer_data_lifecycle>

      </datawriter_qos>


      <!-- === DataReader Configuration: ================================= 
      
      The base configuration of the DataReader object that consumes latency
      data (on the -pub side of the application).

      This element corresponds to the DataReaderQos type, which is described
      in detail in the API Reference HTML documentation. Each child element
      corresponds to a field in that structure with the same name. Any
      parameter not listed here will pick up the documented default value.
      -->
      <datareader_qos>
        <!--
        The default value of reliability.kind is RELIABLE_RELIABILITY_QOS. 
        
        The reliability.kind can be modified to BEST_EFFORT_RELIABILITY_QOS
        by using the command-line option -bestEffort.
        -->
        <reliability>
          <kind>RELIABLE_RELIABILITY_QOS</kind>
        </reliability>

        <!--
        DurabilityQos policy specifies whether or not Connext will store and 
        deliver previously published data samples to new DDSDataReader entities 
        that join the network later.
        
        Important: durability.kind and durability.direct_communication are configured
        automatically within the source code. To modify them, use the input commands
        -durability and -noDirectCommunication.
        
        The default value of _DirectCommunication is true.
        The default value of _Durability is DDS_VOLATILE_DURABILITY_QOS
        
        if _DirectCommunication is false
          if _Durability is DDS_TRANSIENT_DURABILITY_QOS or DDS_PERSISTENT_DURABILITY_QOS
            <durability>
              <kind>_Durability</kind>
              <direct_communication>_DirectCommunication</direct_communication>
            </durability>
        -->
        
        <!--
        The number of samples for which the middleware will set aside space.
        See the comments above for more information.
        -->
        <resource_limits>
          <max_samples>100</max_samples>
          <initial_samples>100</initial_samples>
          <max_samples_per_instance>100</max_samples_per_instance>
        </resource_limits>

        <reader_resource_limits>
          <max_samples_per_remote_writer>100</max_samples_per_remote_writer>
        </reader_resource_limits>

        <!--
        The behavioral contract under which the DataReader will carry out the
        reliability protocol. See the comments above for more information.
        -->
        <protocol>
          <rtps_reliable_reader>
            <min_heartbeat_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </min_heartbeat_response_delay>
            <max_heartbeat_response_delay>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </max_heartbeat_response_delay>
            <heartbeat_suppression_duration>
              <sec>DURATION_ZERO_SEC</sec>
              <nanosec>DURATION_ZERO_NSEC</nanosec>
            </heartbeat_suppression_duration>
          </rtps_reliable_reader>
        </protocol>
      </datareader_qos>
      
    </qos_profile>

    <!-- ================================================================= -->
    <!-- Announcement QoS Profile                                          -->
    <!-- ================================================================= -->

    <!--
    This profile is used by the test harness for the announcement topic,
    which is used to synchronize the publishing and subscribing size
    to start the test.  Basically, the announcement should be sent/received
    reliably.

    Note: this profile derives from the Latency QoS so we do not have to duplicate
    the Reliability QoS protocol settings.
    -->
    <qos_profile name="AnnouncementQos" base_name="LatencyQos">

      <!-- === DataReader Configuration: ================================= -->

      <datareader_qos>
        <reliability>
          <kind>RELIABLE_RELIABILITY_QOS</kind>
          <max_blocking_time>
            <sec>DURATION_INFINITE_SEC</sec>
            <nanosec>DURATION_INFINITE_NSEC</nanosec>
          </max_blocking_time>
        </reliability>
        
        <history>
          <kind>KEEP_ALL_HISTORY_QOS</kind>
        </history>
        <durability>
          <kind>DDS_TRANSIENT_LOCAL_DURABILITY_QOS</kind>
        </durability>
      </datareader_qos>

      <!-- === DataWriter Configuration: ================================= -->

      <datawriter_qos>
        <reliability>
          <kind>RELIABLE_RELIABILITY_QOS</kind>
          <max_blocking_time>
            <sec>DURATION_INFINITE_SEC</sec>
            <nanosec>DURATION_INFINITE_NSEC</nanosec>
          </max_blocking_time>
        </reliability>
        
        <history>
          <kind>KEEP_ALL_HISTORY_QOS</kind>
        </history>
        <durability>
          <kind>DDS_TRANSIENT_LOCAL_DURABILITY_QOS</kind>
        </durability>
      </datawriter_qos>
    </qos_profile>
  </qos_library>
</dds>
